# Hadoop X Spark - Comparing Performance for Workloads 
Code used for university coursework aimed at comparing Hadoop and Spark functionality, with Machine Learning (ML) tasks in mind

This project consists of 2 (plus one discarded task) tasks we ran in order to compare the performance of Hadoop MapReduce and Spark, as well as Mahout (running on top of Hadoop MapReduce) and Spark's MLLib machine learning library.

### The experiments

We ran a standard wordcount experiment over a large dataset using Hadoop and Spark, the results being as follows:

![results1](http://i.imgur.com/qvy6czI.png)


Special thanks to [Julian McAuley](http://cseweb.ucsd.edu/~jmcauley/) for letting us use the dataset prepared by him.

